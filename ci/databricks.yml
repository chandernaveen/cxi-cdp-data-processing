trigger:
  branches:
    include:
    - develop

variables:
- group: cxi-cdp-data-processing
- name: version.MajorMinor
  value: '1.1' # Manually adjust the version number as needed for semantic versioning. Revision is auto-incremented.
- name: version.Revision
  value: $[counter(variables['version.MajorMinor'], 0)]
- name: version.Patсh
  value: $[counter(variables['build.reason'], 0)]
- name: versionNumber
  value: $[format('{0}.{1}', variables['version.MajorMinor'], variables['version.Patсh'])]


name: $(versionNumber)

stages:
- stage: Build
  pool: 
     vmimage: ubuntu-18.04
  jobs:
    - job: run_tests_and_build
      steps:
       - task: UsePythonVersion@0
         inputs:
           versionSpec: '3.8.*'
           addToPath: true
           architecture: 'x64'

       - task: Bash@3
         enabled: true
         displayName: Install Databricks-Connect
         inputs:
           targetType: 'inline'
           script: |
             python -m venv .venv &&
             sbt setupDatabricksConnect

       - task: configuredatabricks@0
         enabled: true
         inputs:
           url: 'https://adb-8464693284532204.4.azuredatabricks.net'
           token: $(BEARERTOKEN)

       - task: databricksClusterTask@0
         displayName: create test cluster
         enabled: false
         inputs:
           authMethod: 'bearer'
           bearerToken: '$(BEARERTOKEN)'
           region: 'eastus2'
           sourcePath: 'ci/test_cluster_config.json'

       - task: startcluster@0
         inputs:
           clusterid: $(EXISTING-CLUSTER-ID)
           failOnStderr: false

       - script: |
          source .venv/bin/activate
          echo "y
              $(WORKSPACE-REGION-URL)
              $(BEARERTOKEN)
              $(EXISTING-CLUSTER-ID)
              $(WORKSPACE-ORG-ID)
              15001" | databricks-connect configure
          databricks-connect test
         displayName: 'Configure databricks-connect'
         enabled: true

       - task: Bash@3
         displayName: Execute tests
         inputs:
           targetType: 'inline'
           script: 'sbt jacoco'

       - task: PublishTestResults@2
         displayName: publish tests result
         inputs:
           testResultsFormat: 'JUnit'
           testResultsFiles: '**/target/test-reports/*.xml'
           searchFolder: '$(Build.SourcesDirectory)'
           mergeTestResults: true
           testRunTitle: 'JUnit'

       - task: PublishCodeCoverageResults@1
         displayName: publish JaCoCo code coverage results
         inputs:
           codeCoverageTool: 'JaCoCo'
           summaryFileLocation: '**/target/scala-2.12/jacoco/report/*.xml'
           reportDirectory: '**/target/scala-2.12/jacoco/report/html/'
           failIfCoverageEmpty: true    
       - task: PublishBuildArtifacts@1
         displayName: publish artifacts
         enabled: true
         inputs:
           PathtoPublish: 'target/scala-2.12/cxi_cdp_data_processing_assembly_2_12.jar'
           ArtifactName: 'cxi_cdp_data_processing_assembly'
           publishLocation: 'Container'

            

- stage: Sonar_Qube
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/develop'))
  pool: kube-agent
  jobs:
      - job:
        steps:
          - task: SonarQubePrepare@4
            enabled: true
            inputs:
              SonarQube: 'sonar'
              scannerMode: 'CLI'
              configMode: 'manual'
              cliProjectKey: 'cxi-cdp-data-processing'
              cliSources: '.'
          - task: SonarQubeAnalyze@4
            enabled: true
          - task: SonarQubePublish@5
            inputs:
              pollingTimeoutSec: '300'
